{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PureMic Dataset Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve,average_precision_score, precision_recall_curve, auc, make_scorer, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "DATA_ROOT='D:\\CastelBranco\\PAPER'\n",
    "all_files=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "The puremic data is provided in a python-friendly format just like openmic-2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUREMIC = np.load(os.path.join(DATA_ROOT, 'PureMic.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y', 'sample_key']\n"
     ]
    }
   ],
   "source": [
    "print(list(PUREMIC.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's included in the data?\n",
    "- X: 20000 91 128 array of VGGish features\n",
    "    - First index (0..1049) corresponds to the sample key\n",
    "    - Second index (0..90) corresponds to the 91, 100 ms hop frames (each time slice is 960 ms long). \n",
    "    - Third index (0..127) corresponds to the VGGish features at each point in the 10sec clip\n",
    "    - Example X[40, 8] is the 128-dimensional feature vector for the 9th time slice in the 41st example\n",
    "\n",
    "- Y_true: 1050 21 one hot encoded label array\n",
    "    - First index corresponds to sample key, as above\n",
    "    - Second index corresponds to the label class (accordion, ..., zilence)\n",
    "    - Example: Y[40, 4] indicates the confidence that example #41 contains the 5th instrument\n",
    "\n",
    "- sample_key: 1050 array of sample key strings\n",
    "    - Example: sample_key[40] is the sample key for example #41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_PureMic, Y_PureMic, sample_key_PureMic = PUREMIC['X'], PUREMIC['Y'], PUREMIC['sample_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accordion': 0, 'banjo': 1, 'bass': 2, 'cello': 3, 'clarinet': 4, 'cymbals': 5, 'drums': 6, 'flute': 7, 'guitar': 8, 'mallet_percussion': 9, 'mandolin': 10, 'organ': 11, 'piano': 12, 'saxophone': 13, 'synthesizer': 14, 'trombone': 15, 'trumpet': 16, 'ukulele': 17, 'violin': 18, 'voice': 19, 'zilence': 20}\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(DATA_ROOT, 'class-map.json'), 'r') as f:\n",
    "    class_map = json.load(f)\n",
    "\n",
    "#%%\n",
    "classes=[]\n",
    "for value in class_map:\n",
    "    classes.append(value)\n",
    "    \n",
    "classes=np.array(classes)\n",
    "print(class_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading train and test splits\n",
    "PureMic also provides a pre-defined train-test split. The sets are perfectly balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train = pd.read_csv(os.path.join(DATA_ROOT,'train_split.csv'), \n",
    "                          header=None, squeeze=True)\n",
    "\n",
    "split_test = pd.read_csv(os.path.join(DATA_ROOT,'test_split.csv'), \n",
    "                          header=None, squeeze=True)\n",
    "\n",
    "train_set = set(split_train)\n",
    "test_set = set(split_test)\n",
    "\n",
    "\n",
    "idx_train, idx_test = [], []\n",
    "\n",
    "for idx, n in enumerate(sample_key_PureMic):\n",
    "    if n in train_set:\n",
    "        idx_train.append(idx)\n",
    "    elif n in test_set:\n",
    "        idx_test.append(idx)\n",
    "    else:\n",
    "        # This should never happen, but better safe than sorry.\n",
    "        raise RuntimeError('Unknown sample key={}! Abort!'.format(sample_key_PureMic[n]))\n",
    "        \n",
    "# Finally, cast the idx_* arrays to numpy structures\n",
    "idx_train = np.asarray(idx_train)\n",
    "idx_test = np.asarray(idx_test)\n",
    "\n",
    "\n",
    "# Finally, we use the split indices to partition the features, labels, and masks\n",
    "X_train_pm = X_PureMic[idx_train]\n",
    "X_test_pm = X_PureMic[idx_test]\n",
    "\n",
    "Y_train_pm = Y_PureMic[idx_train]\n",
    "Y_test_pm = Y_PureMic[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train: 840,  # Test: 210\n"
     ]
    }
   ],
   "source": [
    "# Number of train and test examples (80%/20%)\n",
    "print('# Train: {},  # Test: {}'.format(len(split_train), len(split_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(840, 91, 128)\n",
      "(210, 91, 128)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pm.shape)\n",
    "print(X_test_pm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_PM_MEAN_TRAIN = np.mean(X_train_pm, axis=1)\n",
    "X_PM_MEAN_TEST = np.mean(X_test_pm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        accordion       1.00      1.00      1.00        10\n",
      "            banjo       1.00      1.00      1.00        10\n",
      "             bass       1.00      1.00      1.00        10\n",
      "            cello       1.00      0.90      0.95        10\n",
      "         clarinet       1.00      0.90      0.95        10\n",
      "          cymbals       1.00      0.70      0.82        10\n",
      "            drums       0.80      0.80      0.80        10\n",
      "            flute       1.00      1.00      1.00        10\n",
      "           guitar       0.91      1.00      0.95        10\n",
      "mallet_percussion       0.91      1.00      0.95        10\n",
      "         mandolin       1.00      0.90      0.95        10\n",
      "            organ       1.00      1.00      1.00        10\n",
      "            piano       1.00      0.90      0.95        10\n",
      "        saxophone       0.90      0.90      0.90        10\n",
      "      synthesizer       0.91      1.00      0.95        10\n",
      "         trombone       1.00      1.00      1.00        10\n",
      "          trumpet       1.00      0.90      0.95        10\n",
      "          ukulele       0.91      1.00      0.95        10\n",
      "           violin       0.83      1.00      0.91        10\n",
      "            voice       0.77      1.00      0.87        10\n",
      "          zilence       1.00      0.90      0.95        10\n",
      "\n",
      "        micro avg       0.94      0.94      0.94       210\n",
      "        macro avg       0.95      0.94      0.94       210\n",
      "     weighted avg       0.95      0.94      0.94       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#FIT NN_MEAN \n",
    "tf.keras.backend.clear_session()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "num_classes=21\n",
    "img_input = Input(shape=(128,))\n",
    "n=Dense(512, activation='sigmoid')(img_input)\n",
    "n=Dense(256, activation='sigmoid')(n)\n",
    "n=Dense(num_classes, activation='softmax')(n)\n",
    "NN_MEAN=Model(img_input,n)\n",
    "\n",
    "opt= SGD(lr=0.001)\n",
    "NN_MEAN.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', \n",
    "                        min_delta=1e-3, \n",
    "                        patience=8, verbose=2, mode='auto')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, \n",
    "                                            verbose=0, mode='auto', \n",
    "                                            min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "if all_files:\n",
    "    NN_MEAN.load_weights(os.path.join(DATA_ROOT,'models','NN_MEAN.h5'))\n",
    "else:\n",
    "    NN_MEAN.fit(X_PM_MEAN_TRAIN,Y_train_pm,validation_data=(X_PM_MEAN_TEST,Y_test_pm),callbacks=[monitor,reduce_lr],verbose=2,epochs=2000)\n",
    "    NN_MEAN.save_weights(os.path.join(DATA_ROOT,'models','NN_MEAN.h5'))    \n",
    "\n",
    "scores_pm_mean=NN_MEAN.predict_on_batch(X_PM_MEAN_TEST)\n",
    "\n",
    "print(classification_report(np.argmax(Y_test_pm,axis=1), np.argmax(scores_pm_mean,axis=1),target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of PM_ALL: 95550\n"
     ]
    }
   ],
   "source": [
    "#%% Create PM_ALL\n",
    "\n",
    "X_PM_ALL=[]\n",
    "Y_PM_ALL=[]\n",
    "samp_info_all_pm=[]\n",
    "\n",
    "for idx, clip in enumerate(X_PureMic):\n",
    "    for sec, instance in enumerate(clip):\n",
    "        X_PM_ALL.append(instance)\n",
    "        Y_PM_ALL.append(Y_PureMic[idx])\n",
    "        samp_info_all_pm.append([sample_key_PureMic[idx],sec])\n",
    "            \n",
    "X_PM_ALL=np.array(X_PM_ALL)\n",
    "Y_PM_ALL=np.array(Y_PM_ALL)\n",
    "samp_info_all_pm=np.array(samp_info_all_pm)\n",
    "\n",
    "print('Size of PM_ALL: {}'.format(len(X_PM_ALL)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'accordion': 4550,\n",
       "         'banjo': 4550,\n",
       "         'bass': 4550,\n",
       "         'cello': 4550,\n",
       "         'clarinet': 4550,\n",
       "         'cymbals': 4550,\n",
       "         'drums': 4550,\n",
       "         'flute': 4550,\n",
       "         'guitar': 4550,\n",
       "         'mallet_percussion': 4550,\n",
       "         'mandolin': 4550,\n",
       "         'organ': 4550,\n",
       "         'piano': 4550,\n",
       "         'saxophone': 4550,\n",
       "         'synthesizer': 4550,\n",
       "         'trombone': 4550,\n",
       "         'trumpet': 4550,\n",
       "         'ukulele': 4550,\n",
       "         'violin': 4550,\n",
       "         'voice': 4550,\n",
       "         'zilence': 4550})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% convert one hot enconded to categorical so we can see the class distribution\n",
    "pm_labels=[]\n",
    "\n",
    "for n in Y_PM_ALL:\n",
    "    inst_class=classes[np.where(n==1)[0][0]]\n",
    "    pm_labels.append(inst_class)\n",
    "    \n",
    "collections.Counter(pm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get PM_ALL scores with NN_MEAN\n",
    "scores_pm_all=NN_MEAN.predict(X_PM_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of PM_ALL: 84020\n"
     ]
    }
   ],
   "source": [
    "#create PM_1\n",
    "thresh_sil=0.5\n",
    "thresh_up=0.2\n",
    "\n",
    "sil_label=np.zeros(21,dtype=np.int32)\n",
    "sil_label[20]=1\n",
    "\n",
    "X_PM1=[]\n",
    "Y_PM1=[]\n",
    "N_PM1=[]\n",
    "\n",
    "for idx in range(len(X_PM_ALL)):    \n",
    "    \n",
    "    if scores_pm_all[idx,20]>thresh_sil: #look for silence instances in all classes\n",
    "        X_PM1.append(X_PM_ALL[idx])\n",
    "        Y_PM1.append(sil_label)\n",
    "        N_PM1.append(samp_info_all_pm[idx])\n",
    "    \n",
    "    else:\n",
    "        classe=np.where(Y_PM_ALL[idx]==1)[0][0] #get the class index of current instance\n",
    "        proba=scores_pm_all[idx,classe] #get the score only of the corresponding class\n",
    "        if proba > thresh_up:           #even belonging to same classe the activation should be greater than thresh_up\n",
    "            X_PM1.append(X_PM_ALL[idx])\n",
    "            Y_PM1.append(Y_PM_ALL[idx])\n",
    "            N_PM1.append(samp_info_all_pm[idx])\n",
    "        \n",
    "\n",
    "X_PM1=np.array(X_PM1)\n",
    "Y_PM1=np.array(Y_PM1)\n",
    "N_PM1=np.array(N_PM1)\n",
    "\n",
    "print('Size of PM_ALL: {}'.format(len(X_PM1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'accordion': 4273,\n",
       "         'zilence': 4809,\n",
       "         'banjo': 4126,\n",
       "         'bass': 4020,\n",
       "         'cello': 3673,\n",
       "         'clarinet': 3691,\n",
       "         'cymbals': 3781,\n",
       "         'drums': 4156,\n",
       "         'flute': 4145,\n",
       "         'guitar': 4052,\n",
       "         'mallet_percussion': 4036,\n",
       "         'mandolin': 4188,\n",
       "         'organ': 3995,\n",
       "         'piano': 4053,\n",
       "         'saxophone': 3273,\n",
       "         'synthesizer': 3945,\n",
       "         'trombone': 3901,\n",
       "         'trumpet': 3683,\n",
       "         'ukulele': 3932,\n",
       "         'violin': 3981,\n",
       "         'voice': 4307})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert one hot enconded to categorical so we can see the class distribution\n",
    "#this time, the number of instances should increase for silence class and decrease to the remaining\n",
    "pm1_labels=[]\n",
    "\n",
    "for n in Y_PM1:\n",
    "    inst_class=classes[np.where(n==1)[0][0]]\n",
    "    pm1_labels.append(inst_class)\n",
    "    \n",
    "collections.Counter(pm1_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split again in train-test, this time with labels per instance and not per clip\n",
    "idx_train, idx_test = [], []\n",
    "\n",
    "for idx, n in enumerate(N_PM1):\n",
    "    if n[0] in train_set:\n",
    "        idx_train.append(idx)\n",
    "    elif n[0] in test_set:\n",
    "        idx_test.append(idx)\n",
    "    else:\n",
    "        raise RuntimeError('Unknown sample key={}! Abort!'.format(sample_key_PureMic[n]))\n",
    "        \n",
    "idx_train_pm1 = np.asarray(idx_train)\n",
    "idx_test_pm1 = np.asarray(idx_test)\n",
    "\n",
    "X_PM1_TRAIN=X_PM1[idx_train_pm1]\n",
    "Y_PM1_TRAIN=Y_PM1[idx_train_pm1]\n",
    "\n",
    "X_PM1_TEST=X_PM1[idx_test_pm1]\n",
    "Y_PM1_TEST=Y_PM1[idx_test_pm1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        accordion       0.96      0.99      0.98       887\n",
      "            banjo       1.00      0.99      1.00       799\n",
      "             bass       0.96      0.97      0.96       793\n",
      "            cello       0.94      0.94      0.94       682\n",
      "         clarinet       0.94      0.89      0.91       703\n",
      "          cymbals       0.98      0.93      0.96       567\n",
      "            drums       0.95      0.98      0.96       699\n",
      "            flute       0.97      0.99      0.98       870\n",
      "           guitar       0.99      0.86      0.92       735\n",
      "mallet_percussion       0.99      0.96      0.98       776\n",
      "         mandolin       0.96      0.94      0.95       822\n",
      "            organ       0.96      1.00      0.98       736\n",
      "            piano       0.96      0.98      0.97       678\n",
      "        saxophone       0.85      0.94      0.89       578\n",
      "      synthesizer       0.96      0.97      0.97       799\n",
      "         trombone       0.93      0.95      0.94       725\n",
      "          trumpet       0.90      0.91      0.90       606\n",
      "          ukulele       0.89      0.95      0.92       813\n",
      "           violin       0.97      0.88      0.92       855\n",
      "            voice       0.98      1.00      0.99       892\n",
      "          zilence       0.98      0.98      0.98       866\n",
      "\n",
      "        micro avg       0.95      0.95      0.95     15881\n",
      "        macro avg       0.95      0.95      0.95     15881\n",
      "     weighted avg       0.96      0.95      0.95     15881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "num_classes=21\n",
    "img_input = Input(shape=(128,))\n",
    "n=Dense(4096, activation='sigmoid')(img_input)\n",
    "n=Dense(2048, activation='sigmoid')(n)\n",
    "n=Dense(num_classes, activation='softmax')(n)\n",
    "NN_ALL=Model(img_input,n)\n",
    "\n",
    "opt = Adam(lr=0.001, decay=1e-6)\n",
    "opt= SGD(lr=0.001)\n",
    "NN_ALL.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', \n",
    "                        min_delta=1e-3, \n",
    "                        patience=8, verbose=2, mode='auto')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, \n",
    "                                            verbose=0, mode='auto', \n",
    "                                            min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "if all_files:\n",
    "    NN_ALL.load_weights(os.path.join(DATA_ROOT,'models','NN_ALL.h5'))\n",
    "    with open(os.path.join(DATA_ROOT,'scores','scores_pm_all'), \"rb\") as fp:   # Unpickling\n",
    "            scores_pm_all = pickle.load(fp)\n",
    "else:\n",
    "    NN_ALL.fit(X_PM1_TRAIN,Y_PM1_TRAIN,validation_data=(X_PM1_TEST,Y_PM1_TEST),callbacks=[monitor,reduce_lr],verbose=2,epochs=1000)\n",
    "    NN_ALL.save_weights(os.path.join(DATA_ROOT,'models','NN_ALL.h5'))\n",
    "    scores_pm_all=NN_ALL.predict(X_PM1_TEST)\n",
    "    with open(os.path.join(DATA_ROOT,'scores','scores_pm_all'), \"wb\") as fp:   # Unpickling\n",
    "        pickle.dump(scores_pm_all, fp,protocol=4)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(np.argmax(Y_PM1_TEST,axis=1), np.argmax(scores_pm_all,axis=1),target_names=classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PM2\n",
    "PM2 is the final dataset as explained in (ref paper).\n",
    "PM2 has examples from AudioSet (without the clips of PureMic) and the training set of OpenMIC. As those dataset are very large we only realease the final result of PM2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(os.path.join(DATA_ROOT,'PM2'), \"rb\") as fp:   # Unpickling\n",
    "            X_PM2,Y_PM2 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'accordion': 50000,\n",
       "         'banjo': 50000,\n",
       "         'bass': 27536,\n",
       "         'cello': 50000,\n",
       "         'clarinet': 28355,\n",
       "         'cymbals': 35886,\n",
       "         'drums': 50000,\n",
       "         'flute': 50000,\n",
       "         'guitar': 50000,\n",
       "         'mallet_percussion': 50000,\n",
       "         'mandolin': 50000,\n",
       "         'organ': 50000,\n",
       "         'piano': 50000,\n",
       "         'saxophone': 50000,\n",
       "         'synthesizer': 50000,\n",
       "         'trombone': 50000,\n",
       "         'trumpet': 50000,\n",
       "         'ukulele': 50000,\n",
       "         'violin': 50000,\n",
       "         'voice': 50000,\n",
       "         'zilence': 50000})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of instances per class\n",
    "collections.Counter(Y_PM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        accordion       0.97      0.99      0.98       887\n",
      "            banjo       0.99      1.00      1.00       799\n",
      "             bass       0.96      0.96      0.96       793\n",
      "            cello       0.95      0.93      0.94       682\n",
      "         clarinet       0.92      0.89      0.91       703\n",
      "          cymbals       0.98      0.93      0.96       567\n",
      "            drums       0.94      0.98      0.96       699\n",
      "            flute       0.97      0.99      0.98       870\n",
      "           guitar       0.99      0.91      0.95       735\n",
      "mallet_percussion       0.99      0.98      0.99       776\n",
      "         mandolin       0.96      0.94      0.95       822\n",
      "            organ       0.97      1.00      0.99       736\n",
      "            piano       0.96      0.99      0.97       678\n",
      "        saxophone       0.87      0.91      0.89       578\n",
      "      synthesizer       0.98      0.97      0.97       799\n",
      "         trombone       0.94      0.95      0.95       725\n",
      "          trumpet       0.90      0.91      0.90       606\n",
      "          ukulele       0.89      0.96      0.92       813\n",
      "           violin       0.96      0.91      0.93       855\n",
      "            voice       0.99      1.00      0.99       892\n",
      "          zilence       0.99      0.98      0.99       866\n",
      "\n",
      "        micro avg       0.96      0.96      0.96     15881\n",
      "        macro avg       0.96      0.96      0.96     15881\n",
      "     weighted avg       0.96      0.96      0.96     15881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "PM2_y_binary = encoder.fit_transform(Y_PM2)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "num_classes=21\n",
    "img_input = Input(shape=(128,))\n",
    "n=Dense(4096, activation='sigmoid')(img_input)\n",
    "n=Dense(2048, activation='sigmoid')(n)\n",
    "n=Dense(num_classes, activation='softmax')(n)\n",
    "NN_FINAL=Model(img_input,n)\n",
    "\n",
    "opt = Adam(lr=0.001, decay=1e-6)\n",
    "opt= SGD(lr=0.001)\n",
    "NN_FINAL.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', \n",
    "                        min_delta=1e-3, \n",
    "                        patience=5, verbose=2, mode='auto')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, \n",
    "                                            verbose=0, mode='auto', \n",
    "                                            min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "if all_files:\n",
    "    NN_FINAL.load_weights(os.path.join(DATA_ROOT,'models','NN_FINAL.h5'))\n",
    "    with open(os.path.join(DATA_ROOT,'scores','scores_pm_final'), \"rb\") as fp:   # Unpickling\n",
    "            scores_pm_final = pickle.load(fp)\n",
    "    \n",
    "else:\n",
    "    NN_FINAL.fit(X_PM2,PM2_y_binary,validation_data=(X_PM1_TEST,Y_PM1_TEST),callbacks=[monitor,reduce_lr],verbose=2,epochs=1000)\n",
    "    NN_FINAL.save_weights(os.path.join(DATA_ROOT,'models','NN_FINAL.h5'))\n",
    "    scores_pm_final=NN_FINAL.predict(X_PM1_TEST)\n",
    "    with open(os.path.join(DATA_ROOT,'scores','scores_pm_final'), \"wb\") as fp:   # Unpickling\n",
    "        pickle.dump(scores_pm_final, fp,protocol=4)\n",
    "\n",
    "\n",
    "print(classification_report(np.argmax(Y_PM1_TEST,axis=1),np.argmax(scores_pm_final,axis=1),target_names=classes))            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358732 missing labels, 23654 negatives, 17614 positives\n"
     ]
    }
   ],
   "source": [
    "#Openmic missing labels\n",
    "OPENMIC = np.load(os.path.join(DATA_ROOT,'OpenMIC', 'openmic-2018.npz'))\n",
    "X_om_final, Y_true_om_final, Y_mask_om_final, sample_key_om_final = OPENMIC['X'], OPENMIC['Y_true'], OPENMIC['Y_mask'], OPENMIC['sample_key']\n",
    "\n",
    "split_train = pd.read_csv(os.path.join(DATA_ROOT, 'OpenMIC','split01_train.csv'), \n",
    "                              header=None, squeeze=True)\n",
    "split_test = pd.read_csv(os.path.join(DATA_ROOT, 'OpenMIC','split01_test.csv'), \n",
    "                     header=None, squeeze=True)\n",
    "\n",
    "train_set = set(split_train)\n",
    "test_set = set(split_test)\n",
    "\n",
    "idx_train, idx_test = [], []\n",
    "\n",
    "for idx, n in enumerate(OM[2]):\n",
    "    if n in train_set:\n",
    "        idx_train.append(idx)\n",
    "    elif n in test_set:\n",
    "        idx_test.append(idx)\n",
    "\n",
    "idx_train = np.asarray(idx_train)\n",
    "idx_test = np.asarray(idx_test)\n",
    "\n",
    "X_train_om = X_om_final[idx_train]\n",
    "X_test_om = X_om_final[idx_test]\n",
    "\n",
    "\n",
    "Y_train_om = Y_true_om_final[idx_train]\n",
    "Y_test_om = Y_true_om_final[idx_test]\n",
    "\n",
    "unlabelled=0\n",
    "positives=0\n",
    "negatives=0\n",
    "for clip in Y_true_om_final:\n",
    "    for inst_class in clip:\n",
    "        if inst_class == 0.5:\n",
    "            unlabelled=unlabelled+1\n",
    "        if inst_class > 0.5:\n",
    "            positives=positives+1\n",
    "        if inst_class < 0.5:\n",
    "            negatives=negatives+1\n",
    "            \n",
    "\n",
    "print('{} missing labels, {} negatives, {} positives'.format(unlabelled,negatives,positives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load already averaged scores\n",
    "test_scores=np.load(os.path.join(DATA_ROOT,'scores','omic_test_mean_scores.npy'))\n",
    "train_scores=np.load(os.path.join(DATA_ROOT,'scores','omic_train_mean_scores.npy'))\n",
    "proposed_thresholds=np.load(os.path.join(DATA_ROOT,'scores','proposed_thresholds.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646 new positive labels\n"
     ]
    }
   ],
   "source": [
    "#create new labels based on proposed threshs \n",
    "#you can try different thresholds and uncoment to generate negative labels too\n",
    "new_omic_y=[]\n",
    "count_pos=0\n",
    "count_neg=0\n",
    "for idx, score in enumerate(train_scores):\n",
    "    labels=[0.5]*20\n",
    "    for inst in range(20):\n",
    "        if Y_train_om[idx,inst] == 0.5:\n",
    "            if score[inst] > proposed_thresholds[inst]:\n",
    "                labels[inst]=1\n",
    "                count_pos=count_pos+1\n",
    "            #elif score[inst] < ###value###:\n",
    "                #labels[inst]=0\n",
    "                #count_neg=count_neg+1\n",
    "        else:\n",
    "            labels[inst]=Y_train_om[idx,inst]\n",
    "    new_omic_y.append(labels)\n",
    "new_omic_y=np.array(new_omic_y) \n",
    "\n",
    "print('{} new positive labels for train_set'.format(count_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenMIC baseline\n",
    "The following code will process openmic baseline with the new labels. Original baseline is available at https://github.com/cosmir/openmic-2018/blob/master/examples/modeling-baseline.ipynb so you can compare the results.\n",
    "mAP (REF PAPER) of openmic baseline is **0.66**.\n",
    "\n",
    "The new proposed labels improves the openmic **original** i.e. to validate, we only changed the training set labels keeping the test set exactly the same so we can compare the results. The new mAP is **0.68** with **1946** new positive labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "accordion\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95      1159\n",
      "         1.0       1.00      0.73      0.84       462\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      1621\n",
      "   macro avg       0.95      0.86      0.90      1621\n",
      "weighted avg       0.93      0.92      0.92      1621\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.97      0.91       423\n",
      "         1.0       0.78      0.35      0.48       115\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       538\n",
      "   macro avg       0.82      0.66      0.69       538\n",
      "weighted avg       0.83      0.84      0.81       538\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "banjo\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98      1148\n",
      "         1.0       0.97      0.93      0.95       614\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1762\n",
      "   macro avg       0.97      0.96      0.96      1762\n",
      "weighted avg       0.97      0.97      0.97      1762\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.89      0.86       338\n",
      "         1.0       0.68      0.56      0.61       140\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       478\n",
      "   macro avg       0.75      0.72      0.74       478\n",
      "weighted avg       0.78      0.79      0.79       478\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "bass\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97      1010\n",
      "         1.0       0.96      0.89      0.92       458\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1468\n",
      "   macro avg       0.96      0.94      0.95      1468\n",
      "weighted avg       0.95      0.95      0.95      1468\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.96      0.89       329\n",
      "         1.0       0.85      0.54      0.66       134\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       463\n",
      "   macro avg       0.84      0.75      0.78       463\n",
      "weighted avg       0.84      0.84      0.83       463\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "cello\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96       866\n",
      "         1.0       0.94      0.96      0.95       740\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1606\n",
      "   macro avg       0.96      0.96      0.96      1606\n",
      "weighted avg       0.96      0.96      0.96      1606\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.79      0.82       259\n",
      "         1.0       0.78      0.85      0.81       226\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       485\n",
      "   macro avg       0.82      0.82      0.82       485\n",
      "weighted avg       0.82      0.82      0.82       485\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "clarinet\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.95      1349\n",
      "         1.0       1.00      0.64      0.78       434\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1783\n",
      "   macro avg       0.95      0.82      0.86      1783\n",
      "weighted avg       0.92      0.91      0.91      1783\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.99      0.89       503\n",
      "         1.0       0.84      0.12      0.21       137\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       640\n",
      "   macro avg       0.82      0.56      0.55       640\n",
      "weighted avg       0.81      0.81      0.74       640\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "cymbals\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.89      0.94       485\n",
      "         1.0       0.94      1.00      0.97       818\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1303\n",
      "   macro avg       0.97      0.95      0.96      1303\n",
      "weighted avg       0.96      0.96      0.96      1303\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.86      0.91       139\n",
      "         1.0       0.94      0.98      0.96       297\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       436\n",
      "   macro avg       0.95      0.92      0.93       436\n",
      "weighted avg       0.94      0.94      0.94       436\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "drums\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.95      0.97       495\n",
      "         1.0       0.97      1.00      0.98       894\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1389\n",
      "   macro avg       0.98      0.97      0.98      1389\n",
      "weighted avg       0.98      0.98      0.98      1389\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.78      0.85       146\n",
      "         1.0       0.89      0.97      0.93       278\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       424\n",
      "   macro avg       0.91      0.87      0.89       424\n",
      "weighted avg       0.91      0.90      0.90       424\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "flute\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96      1050\n",
      "         1.0       0.98      0.87      0.92       632\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1682\n",
      "   macro avg       0.95      0.93      0.94      1682\n",
      "weighted avg       0.95      0.94      0.94      1682\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.87      0.84       387\n",
      "         1.0       0.65      0.54      0.59       175\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       562\n",
      "   macro avg       0.73      0.70      0.71       562\n",
      "weighted avg       0.76      0.77      0.76       562\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "guitar\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.96      0.98       362\n",
      "         1.0       0.98      1.00      0.99       900\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1262\n",
      "   macro avg       0.99      0.98      0.99      1262\n",
      "weighted avg       0.99      0.99      0.99      1262\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.93      0.94       150\n",
      "         1.0       0.97      0.98      0.97       286\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       436\n",
      "   macro avg       0.96      0.95      0.96       436\n",
      "weighted avg       0.96      0.96      0.96       436\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "mallet_percussion\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96       802\n",
      "         1.0       0.91      0.99      0.95       620\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1422\n",
      "   macro avg       0.95      0.96      0.95      1422\n",
      "weighted avg       0.96      0.95      0.96      1422\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.77      0.81       267\n",
      "         1.0       0.74      0.83      0.78       211\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       478\n",
      "   macro avg       0.80      0.80      0.80       478\n",
      "weighted avg       0.80      0.80      0.80       478\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "mandolin\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.97      1185\n",
      "         1.0       0.95      0.94      0.94       664\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1849\n",
      "   macro avg       0.96      0.95      0.95      1849\n",
      "weighted avg       0.96      0.96      0.96      1849\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.85      0.84       434\n",
      "         1.0       0.64      0.61      0.62       193\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       627\n",
      "   macro avg       0.73      0.73      0.73       627\n",
      "weighted avg       0.77      0.77      0.77       627\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "organ\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      1.00      0.93       977\n",
      "         1.0       1.00      0.78      0.88       671\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1648\n",
      "   macro avg       0.93      0.89      0.90      1648\n",
      "weighted avg       0.92      0.91      0.91      1648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.94      0.85       310\n",
      "         1.0       0.67      0.31      0.43       121\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       431\n",
      "   macro avg       0.72      0.63      0.64       431\n",
      "weighted avg       0.75      0.76      0.73       431\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "piano\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.94      0.96       420\n",
      "         1.0       0.98      1.00      0.99      1191\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1611\n",
      "   macro avg       0.99      0.97      0.98      1611\n",
      "weighted avg       0.98      0.98      0.98      1611\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.78      0.88       130\n",
      "         1.0       0.91      1.00      0.95       285\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       415\n",
      "   macro avg       0.95      0.89      0.91       415\n",
      "weighted avg       0.94      0.93      0.93       415\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "saxophone\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.94      0.97       906\n",
      "         1.0       0.94      0.99      0.97       834\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1740\n",
      "   macro avg       0.97      0.97      0.97      1740\n",
      "weighted avg       0.97      0.97      0.97      1740\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.80      0.83       324\n",
      "         1.0       0.80      0.86      0.83       305\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       629\n",
      "   macro avg       0.83      0.83      0.83       629\n",
      "weighted avg       0.83      0.83      0.83       629\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "synthesizer\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.95      0.97       399\n",
      "         1.0       0.98      1.00      0.99      1041\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1440\n",
      "   macro avg       0.99      0.97      0.98      1440\n",
      "weighted avg       0.98      0.98      0.98      1440\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.79      0.86       112\n",
      "         1.0       0.92      0.98      0.95       268\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       380\n",
      "   macro avg       0.93      0.88      0.90       380\n",
      "weighted avg       0.93      0.92      0.92       380\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "trombone\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96      1405\n",
      "         1.0       0.96      0.87      0.91       666\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2071\n",
      "   macro avg       0.95      0.93      0.94      2071\n",
      "weighted avg       0.95      0.95      0.95      2071\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.92      0.87       492\n",
      "         1.0       0.78      0.59      0.67       228\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       720\n",
      "   macro avg       0.80      0.76      0.77       720\n",
      "weighted avg       0.81      0.82      0.81       720\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "trumpet\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96      1303\n",
      "         1.0       0.95      0.92      0.94       879\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2182\n",
      "   macro avg       0.95      0.94      0.95      2182\n",
      "weighted avg       0.95      0.95      0.95      2182\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.87      0.83       467\n",
      "         1.0       0.78      0.67      0.72       318\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       785\n",
      "   macro avg       0.79      0.77      0.78       785\n",
      "weighted avg       0.79      0.79      0.79       785\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "ukulele\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97      1279\n",
      "         1.0       0.96      0.89      0.92       579\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1858\n",
      "   macro avg       0.96      0.94      0.95      1858\n",
      "weighted avg       0.95      0.95      0.95      1858\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.90      0.85       408\n",
      "         1.0       0.70      0.54      0.61       182\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       590\n",
      "   macro avg       0.76      0.72      0.73       590\n",
      "weighted avg       0.78      0.79      0.78       590\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "violin\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.86      0.92       623\n",
      "         1.0       0.90      1.00      0.95       793\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1416\n",
      "   macro avg       0.95      0.93      0.93      1416\n",
      "weighted avg       0.94      0.94      0.94      1416\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.71      0.79       237\n",
      "         1.0       0.85      0.95      0.89       394\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       631\n",
      "   macro avg       0.87      0.83      0.84       631\n",
      "weighted avg       0.86      0.86      0.86       631\n",
      "\n",
      "\n",
      "----------------------------------------------------\n",
      "voice\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.90      0.95       426\n",
      "         1.0       0.95      1.00      0.98       853\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1279\n",
      "   macro avg       0.97      0.95      0.96      1279\n",
      "weighted avg       0.97      0.97      0.97      1279\n",
      "\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.87      0.92       150\n",
      "         1.0       0.92      0.98      0.95       224\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       374\n",
      "   macro avg       0.94      0.93      0.93       374\n",
      "weighted avg       0.94      0.94      0.94       374\n",
      "\n",
      "\n",
      "mAP: 0.6747373075429715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,average_precision_score\n",
    "models = dict()\n",
    "AP_TOT=0\n",
    "\n",
    "for inst in range(20):\n",
    "    \n",
    "        \n",
    "    instrument=classes[inst]\n",
    "    ###TRAIN\n",
    "    score_indexes=new_omic_y[:,inst] != 0.5       \n",
    "    inst_y_train=new_omic_y[score_indexes,inst]\n",
    "    inst_x_train=X_train_om[score_indexes]\n",
    "\n",
    "    inst_binary_scores_train=np.zeros(len(inst_y_train))\n",
    "    for idx,s in enumerate(inst_y_train):\n",
    "        if s > 0.5:\n",
    "            inst_binary_scores_train[idx]=1\n",
    "    \n",
    "    ###TEST\n",
    "    score_indexes=Y_test_om[:,inst] != 0.5       \n",
    "    inst_y_test=Y_test_om[score_indexes,inst]\n",
    "    inst_x_test=X_test_om[score_indexes]\n",
    "\n",
    "    inst_binary_scores_test=np.zeros(len(inst_y_test))\n",
    "    for idx,s in enumerate(inst_y_test):\n",
    "        if s > 0.5:\n",
    "            inst_binary_scores_test[idx]=1        \n",
    "            \n",
    "\n",
    "    X_train = np.mean(inst_x_train, axis=1)\n",
    "    X_test  = np.mean(inst_x_test, axis=1)\n",
    "    \n",
    "\n",
    "    clf = RandomForestClassifier(max_depth=8, n_estimators=100, random_state=0)\n",
    "    \n",
    "\n",
    "    clf.fit(X_train, inst_binary_scores_train)\n",
    "\n",
    "\n",
    "    Y_pred_train = clf.predict(X_train)\n",
    "    Y_pred_test = clf.predict(X_test)\n",
    "    \n",
    "    print('-' * 52)\n",
    "    print(instrument)\n",
    "    print('\\tTRAIN')\n",
    "    print(classification_report(inst_binary_scores_train, Y_pred_train))\n",
    "    print('\\tTEST')\n",
    "    print(classification_report(inst_binary_scores_test, Y_pred_test))\n",
    "    \n",
    "    AP=average_precision_score(inst_binary_scores_test, Y_pred_test, average=None)\n",
    "    AP_TOT=AP_TOT+AP\n",
    "\n",
    "print('mAP: {}'.format(AP_TOT/20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
